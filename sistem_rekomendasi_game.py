# -*- coding: utf-8 -*-
"""Sistem_Rekomendasi_Game.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wGgLx54fP4hgxWRdNWeJltt4hV6IdZsg

# Proyek Analisis Data: [Sistem Rekomendasi Game dengan Collaborative Filtering]
- **Nama:** [Muhammad Rayhan Khadafi]
- **Email:** [A200YBM343@devacademy.id]
- **ID Dicoding:** [A200YBM343]

# 0. Library
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install requests
# %pip install pandas
# %pip install matplotlib
# %pip install scikit-learn
# %pip install tqdm
# %pip install tensorflow
# %pip install protobuf==3.20.*

import requests, time, os
import pandas as pd
from tqdm import tqdm
from tqdm.auto import tqdm as tqdm_auto
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

"""# 1. Scrapping"""

import requests, time, os
import pandas as pd
from tqdm import tqdm

import requests, time
import pandas as pd
from tqdm import tqdm

def get_all_appids():
    """Ambil semua appid dari Steam official API (~150k)."""
    url = 'https://api.steampowered.com/ISteamApps/GetAppList/v2/'
    data = requests.get(url).json()['applist']['apps']
    # data: list of {'appid': int, 'name': str}
    return [app['appid'] for app in data]

def fetch_game(appid):
    """Fetch detail, return dict hanya kalau success & type='game'."""
    url = f'https://store.steampowered.com/api/appdetails?appids={appid}'
    try:
        resp = requests.get(url, timeout=5).json().get(str(appid))
        if resp and resp.get('success'):
            d = resp['data']
            if d.get('type') != 'game':
                return None
            return {
                'appid': appid,
                'title': d.get('name',''),
                'genres': ','.join([g['description'] for g in d.get('genres',[])]),
                'developers': ','.join(d.get('developers',[])),
                'publishers': ','.join(d.get('publishers',[])),
                'tags': ','.join([c['description'] for c in d.get('categories',[])]),
                'release_year': d.get('release_date',{}).get('date','')[-4:],
                'short_description': d.get('short_description','').replace('\n',' ')
            }
    except Exception as e:
        # cetak kalau mau debug
        # print(f"Error fetching {appid}: {e}")
        pass
    return None

# 1. Ambil semua appid
all_appids = get_all_appids()

# 2. Loop sampai dapat 4.000 game valid
TARGET = 4000
games = []
for aid in tqdm(all_appids, desc="Scraping game", total=len(all_appids)):
    if len(games) >= TARGET:
        break
    g = fetch_game(aid)
    if g:
        games.append(g)
    time.sleep(0.2)

df_games = pd.DataFrame(games)
df_games.to_csv('steam_games.csv', index=False)
print(f"Total games scraped: {len(df_games)}")

"""Waktu scrapping 4000 game untuk dataset memakan waktu 4 jam 16 menit

## Menambah dataset (jika perlu)
"""

# Load CSV lama
existing_df = pd.read_csv('steam_games.csv')
existing_appids = set(existing_df['appid'].astype(int).tolist())

# Ambil semua appid dari Steam
def get_all_appids():
    url = 'https://api.steampowered.com/ISteamApps/GetAppList/v2/'
    data = requests.get(url).json()['applist']['apps']
    return [app['appid'] for app in data]

all_appids = get_all_appids()

# Filter appid baru
to_scrape = [a for a in all_appids if a not in existing_appids]

# Fungsi fetch seperti sebelumnya
def fetch_game(appid):
    url = f'https://store.steampowered.com/api/appdetails?appids={appid}'
    try:
        resp = requests.get(url, timeout=5).json().get(str(appid))
        if resp and resp.get('success') and resp['data'].get('type')=='game':
            d = resp['data']
            return {
                'appid': appid,
                'title': d.get('name',''),
                'genres': ','.join([g['description'] for g in d.get('genres',[])]),
                'developers': ','.join(d.get('developers',[])),
                'publishers': ','.join(d.get('publishers',[])),
                'tags': ','.join([c['description'] for c in d.get('categories',[])]),
                'release_year': d.get('release_date',{}).get('date','')[-4:],
                'short_description': d.get('short_description','').replace('\n',' ')
            }
    except:
        return None

# Loop dan append
new_games = []
TARGET_NEW = 2000  # misal ingin tambah 2.000 game baru
for aid in tqdm(to_scrape, desc="Scraping tambahan"):
    if len(new_games) >= TARGET_NEW:
        break
    g = fetch_game(aid)
    if g:
        new_games.append(g)
    time.sleep(0.2)

# Gabungkan, drop duplikat, dan simpan
df_new = pd.DataFrame(new_games)
combined = pd.concat([existing_df, df_new], ignore_index=True)
# Drop jika ada judul atau appid ganda
combined = combined.drop_duplicates(subset=['appid', 'title'])
combined.to_csv('steam_games.csv', index=False)

print(f"Awalnya: {len(existing_df)} baris")
print(f"Baru ditambahkan: {len(df_new)} baris")
print(f"Total sekarang: {len(combined)} baris")

"""# 2. Loading Dataset"""

import pandas as pd

df = pd.read_csv('steam_games.csv')
df = df.dropna(subset=['appid','title']).drop_duplicates('appid')
df['release_year'] = pd.to_numeric(df['release_year'], errors='coerce').fillna(0).astype(int)
df.head()

df.head()
print("Jumlah missing value per kolom:")
print(df.isnull().sum())

"""Mengecek jumlah nilai kosong (missing value) per kolom."""

print("Tipe data per kolom:")
print(df.dtypes)

"""Mengecek tipe data per kolom"""

# Bersihkan missing value di kolom penting
df['genres'] = df['genres'].fillna('').astype(str)
df['tags'] = df['tags'].fillna('').astype(str)
df['short_description'] = df['short_description'].fillna('').astype(str)

# Hilangkan baris yang tidak punya title atau appid (jika ada)
df.dropna(subset=['appid', 'title'], inplace=True)

# Konversi release_year ke numerik
df['release_year'] = pd.to_numeric(df['release_year'], errors='coerce')

"""- Membersihkan nilai kosong pada kolom `genres`, `tags`, dan `short_description` dengan menggantinya menjadi string kosong (`''`).
- Menghapus baris yang tidak memiliki `appid` atau `title` (jika ada).
- Mengonversi `release_year` menjadi numerik untuk visualisasi dan analisis.

# 3. EDA
"""

import matplotlib.pyplot as plt
import numpy as np
from pandas.plotting import scatter_matrix

"""## 3.1 Distribusi Jumlah Game Berdasarkan Tahun Rilis"""

# Ubah kolom release_year ke numerik (jika belum), abaikan error/NaN
df['release_year'] = pd.to_numeric(df['release_year'], errors='coerce')

# Filter data hanya dari 2000 hingga 2024
df_filtered = df[(df['release_year'] >= 2000) & (df['release_year'] <= 2024)]

# Hitung jumlah game per tahun
year_counts = df_filtered['release_year'].value_counts().sort_index()

# Plot horizontal bar chart
plt.figure(figsize=(8, 10))
plt.barh(year_counts.index.astype(int), year_counts.values, color='skyblue', edgecolor='black')
plt.title("Jumlah Game per Tahun Rilis (2000–2024)")
plt.xlabel("Jumlah Game")
plt.ylabel("Tahun Rilis")
plt.yticks(ticks=range(2000, 2025), labels=range(2000, 2025))
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""Berdasarkan 4000 dataset hasil scrapping, mayoritas game di dataset dirilis tahun 2015

# 3.2 Top 15 Genre Game
"""

# Top 15 genre paling sering (horizontal bar chart)
all_genres = df['genres'].str.split(',', expand=True).stack().value_counts().head(15)

plt.figure(figsize=(10, 8))
all_genres.plot.barh(color='skyblue', edgecolor='black')
plt.title("Top 15 Genre Paling Sering Muncul")
plt.xlabel("Jumlah Game")
plt.ylabel("Genre")
plt.gca().invert_yaxis()  # Agar genre dengan count tertinggi berada di atas
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""Berdasarkan 4000 dataset hasil scrapping, mayoritas game di dataset memiliki genre indie, Itu valid karena lebih banyak game buatan developer game independen di seluruh dunia daripada game buatan perusahaan yang dirilis tiap tahun nya.

## 3.3 Heatmap Matrix
"""

# Plot heatmap dengan matplotlib
plt.figure(figsize=(6, 5))
plt.imshow(corr, interpolation='nearest', aspect='auto')
plt.colorbar(label='Correlation coefficient')

# Atur ticks
labels = corr.columns
plt.xticks(np.arange(len(labels)), labels, rotation=45, ha='right')
plt.yticks(np.arange(len(labels)), labels)
plt.title("Heatmap Korelasi Fitur Numerik")
plt.tight_layout()
plt.show()

"""Korelasi:
- release_year tidak berkorelasi dengan num_genres maupun num_tags.
- num_genres hanya sedikit berkorelasi dengan num_tags (ditunjukkan oleh warna agak keunguan tapi tidak gelap total).
- Diagonal selalu bernilai 1.0 (kuning), karena fitur dikorelasikan dengan dirinya sendiri.

Kesimpulan:
Fitur numerik dalam dataset ini tidak saling berkorelasi secara signifikan.

## 3.4 Pairplot
"""

filtered_df = df[(df['release_year'] >= 2000) & (df['release_year'] <= 2024)]

plt.figure(figsize=(10, 10))
scatter_matrix(
    filtered_df[['release_year', 'num_genres', 'num_tags']],
    figsize=(10, 10),
    diagonal='hist',
    alpha=0.5,
    marker='o'
)
plt.suptitle("Pairplot Fitur Numerik (Tahun Rilis 2000–2024)", y=0.92)
plt.tight_layout()
plt.show()

"""- Game modern (2010 ke atas) cenderung memiliki lebih banyak tag, mencerminkan metadata atau kategorisasi yang lebih kaya.
- Tidak ada hubungan linier kuat, tetapi pola visual menyarankan kemungkinan korelasi lemah antara jumlah genre dan tag.
- Distribusi waktu memperlihatkan bahwa data didominasi oleh game yang dirilis pada dekade terakhir.
- Fokus pada tren modern dalam desain dan metadata game.
- Cocok digunakan sebagai dasar eksplorasi fitur untuk rekomendasi berbasis konten atau analisis tren game modern.

# 4. MODEL TRAINING

## Pre-Training
"""

import numpy as np
from sklearn.model_selection import train_test_split

np.random.seed(42)
ratings = pd.DataFrame({
    'userID': np.random.randint(1,1001, size=len(df)),
    'itemID': df['appid'].values,
    'rating': np.random.randint(1,6, size=len(df))
})

# encode user/item jadi index
ratings['user'] = ratings['userID'].astype('category').cat.codes
ratings['item'] = ratings['itemID'].astype('category').cat.codes
n_users = ratings['user'].nunique(); n_items = ratings['item'].nunique()

train, test = train_test_split(ratings, test_size=0.2, random_state=42)

"""Membuat DataFrame ratings:
- userID: Membuat ID acak antara 1–1000 sebagai representasi pengguna.
- itemID: Menggunakan kolom appid dari DataFrame game sebagai ID item/game.
- rating: Membuat rating acak dari 1–5 untuk setiap pasangan user–item.
Membagi dataset ratings menjadi:
- 80% untuk training set
- 20% untuk test set

Dengan random_state=42 untuk hasil pembagian yang tetap.
"""

def pct_within_1(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred) <= 1) * 100

"""Menghitung persentase prediksi yang berada dalam jarak kesalahan maksimal 1 poin dari nilai sebenarnya.

## Training

## ANN

Melakukan Training dengan ANN
"""

import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout
from tensorflow.keras.models import Model
from sklearn.metrics import mean_squared_error
import pandas as pd

# Ubah epochs semua model jadi 2000
configs = {
    'shallow': {'layers':[64],        'epochs':500},
    'medium' : {'layers':[128,64],    'epochs':500},
    'deep'   : {'layers':[256,128,64],'epochs':500}
}

n_users = ratings['user'].nunique()
n_items = ratings['item'].nunique()

def build_model(hidden_layers, embedding_size=32, dropout=0.3):
    u_in = Input(shape=(1,))
    i_in = Input(shape=(1,))

    u_emb = Flatten()(Embedding(n_users, embedding_size)(u_in))
    i_emb = Flatten()(Embedding(n_items, embedding_size)(i_in))

    x = Concatenate()([u_emb, i_emb])

    for units in hidden_layers:
        x = Dense(units, activation='relu')(x)
        x = Dropout(dropout)(x)

    out = Dense(1, activation='linear')(x)

    model = Model(inputs=[u_in, i_in], outputs=out)
    model.compile(optimizer='adam', loss='mse')
    return model

results = {}
for name, cfg in configs.items():
    print(f"\n-- Training {name.upper()} ({cfg['epochs']} epochs)")
    m = build_model(cfg['layers'])

    # Training
    m.fit(
        [train.user, train.item],
        train.rating,
        validation_data=([test.user, test.item], test.rating),
        epochs=cfg['epochs'],
        batch_size=50,
        verbose=1
    )
    # Evaluasi
    pred = m.predict([test.user, test.item], batch_size=50).flatten()
    pct = pct_within_1(test.rating.values, pred)
    mse = mean_squared_error(test.rating.values, pred)

    # Simpan hasil dan model
    results[name] = {'pct_±1': pct, 'MSE': mse, 'model': m}

# Tampilkan hasil evaluasi (jangan timpa `results`)
pd.DataFrame({k: {'pct_±1': v['pct_±1'], 'MSE': v['MSE']} for k, v in results.items()}).T

for name in results:
    print(f"\nSummary untuk model {name.upper()}")
    results[name]['model'].summary()

"""## 5. Evaluasi

Save Model
"""

best_name = max(results, key=lambda k: results[k]['pct_±1'])
best_model = results[best_name]['model']
best_model.save('best_model_keras.h5')
print("Model terbaik:", best_name, "-> pct_±1 =", results[best_name]['pct_±1'])

"""Akurasi terbaik setelah digunakan berbagai tipe training, akurasi tertinggi ialah 42%. Karena tidak ada minimal akurasi 85% jadi dilanjutkan."""

best_model.summary()

"""# 6. Save Model"""

import pickle

best_model.save('best_model_keras.h5')

# Simpan mapping userID/itemID ke index
with open('mapping.pkl','wb') as f:
    pickle.dump({
        'user_codes': dict(zip(ratings['userID'], ratings['user'])),
        'item_codes': dict(zip(ratings['item'], ratings['itemID']))
    }, f)
print("Model dan mapping tersimpan.")

"""# 7. Inferensi CBF (Content Based Filtering)"""

df['genres'] = df['genres'].fillna('').astype(str)
df['tags'] = df['tags'].fillna('').astype(str)
df['combined'] = df['genres'] + ' ' + df['tags']

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Siapkan input pengguna (ubah ini sesuai preferensi)
input_genres = ['Action', 'Adventure']
input_tags = ['Multiplayer', 'Co-op']

input_text = ' '.join(input_genres) + ' ' + ' '.join(input_tags)

# Hitung vektor dan kemiripan
vectorizer = CountVectorizer()
matrix = vectorizer.fit_transform(df['combined'].tolist() + [input_text])

input_vec = matrix[-1]
game_vecs = matrix[:-1]

similarities = cosine_similarity(input_vec, game_vecs).flatten()
df['similarity'] = similarities

# Tampilkan Top-N rekomendasi
top_n = 10
cbf_recommendations = df.sort_values(by='similarity', ascending=False).head(top_n)
cbf_recommendations[['title', 'genres', 'tags', 'release_year', 'similarity']]

"""Bagian ini menampilkan Top-N rekomendasi berdasarkan input genre dan tag yang dimasukkan secara manual oleh user.

Rekomendasi dihitung berdasarkan kemiripan cosine antara kombinasi `genres + tags` game dengan preferensi user.

## Inferensi ID User
"""

# Ambil model terbaik dari hasil evaluasi
best_name = max(results, key=lambda k: results[k]['pct_±1'])
best_model = results[best_name]['model']
print(f"Model terbaik: {best_name.upper()}")

# Pilih satu user untuk diuji (ganti dengan user lain jika mau)
target_user = 42  # bisa diganti dengan user lain yang ada di ratings['user']
all_items = np.arange(n_items)

# Prediksi rating untuk semua item
user_input = np.full(shape=(n_items,), fill_value=target_user)
predicted_ratings = best_model.predict([user_input, all_items], batch_size=64).flatten()

# Ambil item yang sudah pernah dirating oleh user ini
rated_items = train[train.user == target_user]['item'].tolist()
unrated_items = [i for i in all_items if i not in rated_items]

# Prediksi hanya untuk item yang belum pernah dirating
user_input_unrated = np.full(shape=(len(unrated_items),), fill_value=target_user)
pred_unrated = best_model.predict([user_input_unrated, np.array(unrated_items)], batch_size=64).flatten()

# Ambil Top-N
top_n = 10
top_indices = pred_unrated.argsort()[::-1][:top_n]
top_item_ids = [unrated_items[i] for i in top_indices]

# Konversi kembali ke appid
item_id_to_appid = {v: k for k, v in ratings[['itemID', 'item']].drop_duplicates().values}
top_appids = [item_id_to_appid[i] for i in top_item_ids]

# Tampilkan rekomendasi game
df_rekomendasi_cf = df[df['appid'].isin(top_appids)][['title', 'genres', 'release_year']]
df_rekomendasi_cf.reset_index(drop=True, inplace=True)
df_rekomendasi_cf

"""Menggunakan model ANN terbaik, sistem ini memprediksi semua game yang belum pernah dimainkan oleh user tertentu, kemudian menampilkan 10 game dengan prediksi rating tertinggi sebagai rekomendasi.

## Evaluasi CBF dengan Precision@K

Precision@K mengukur berapa banyak dari K item teratas yang relevan dengan preferensi user (misalnya item dengan rating ≥ 4).  
Semakin tinggi Precision@K, semakin akurat sistem dalam menyarankan item yang benar-benar disukai user.
"""

def precision_at_k_all_users(cbf_recommendations, ratings, K=5, rating_threshold=4):
    user_ids = ratings['userID'].unique()
    total_hits = 0
    total_users = 0
    precisions = []

    for user_id in user_ids:
        try:
            # Encode userID jadi user index
            user_index = ratings[ratings['userID'] == user_id]['user'].iloc[0]

            # Ambil item yang dianggap relevan (rating >= threshold)
            user_rated_high = ratings[(ratings['user'] == user_index) & (ratings['rating'] >= rating_threshold)]
            relevant_items = user_rated_high['itemID'].values

            # Ambil Top-K rekomendasi appid
            recommended_appids = cbf_recommendations['appid'].tolist()[:K]

            if len(relevant_items) == 0:
                continue  # user tidak punya data relevan, skip

            # Hitung precision
            hit = sum([1 for appid in recommended_appids if appid in relevant_items])
            precision = hit / K
            precisions.append(precision)
            total_users += 1
            total_hits += hit

        except Exception:
            continue  # lewati user jika error (misal: mapping user tidak ditemukan)

    if total_users == 0:
        return 0.0

    avg_precision = sum(precisions) / total_users
    print(f"Rata-rata Precision@{K} dari {total_users} user = {avg_precision:.4f}")
    return avg_precision

"""Simulasi atau laporan yang mengevaluasi rekomendasi yang sama (cbf_recommendations) untuk semua user"""

precision_at_k_all_users(cbf_recommendations, ratings, K=5)

"""Dari seluruh pengguna, hanya sekitar 0.07% dari Top-5 rekomendasi yang cocok dengan item yang pernah mereka beri rating tinggi."""